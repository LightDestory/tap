{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Spark RDD and Beyond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Types of RDD\n",
    "\n",
    "- ParallelCollectionRDD — An RDD created by Spark Context through parallelizing an existing collection. Eg. sc.parallelize, sc.makeRDD\n",
    "- CoGroupedRDD — An RDD that cogroups its parents. For each key k in parent RDDs, the resulting RDD contains a tuple with the list of values for that key.\n",
    "- HadoopRDD is an RDD that provides core functionality for reading data stored in HDFS using the older MapReduce API. The most notable use case is the return RDD of SparkContext.textFile.\n",
    "- MapPartitionsRDD — An RDD that applies the provided function to every partition of the parent RDD. A result of calling operations like map, flatMap, filter, mapPartitions, etc.\n",
    "- CoalescedRDD — a result of repartition or coalesce transformations.\n",
    "- ShuffledRDD — a result of shuffling, e.g. after repartition or coalesce transformations.\n",
    "- PipedRDD — an RDD created by piping elements to a forked external process.\n",
    "- SequenceFileRDD — is an RDD that can be saved as a SequenceFile.\n",
    "\n",
    "https://medium.com/knoldus/rdd-sparks-fault-tolerant-in-memory-weapon-130f8df2f996"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's do practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'findspark' from '/home/nics/anaconda3/lib/python3.7/site-packages/findspark.py'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "import pyspark\n",
    "findspark.find() \n",
    "findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.24.253.44:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Tap</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=Tap>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = pyspark.SparkConf().setAppName('Tap').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[1] at parallelize at PythonRDD.scala:195"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RDD \n",
    "digits = sc.parallelize([0,1,2,3,4,5,6,7,8,9])\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Trasformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://i.ytimg.com/vi/2IQxywxlMO8/hqdefault.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Transformation return a new RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## map(func)\t\n",
    "Return a new distributed dataset formed by passing each element of the source through a function func. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[5] at collect at <ipython-input-52-e6611284cd92>:2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squares=digits.map(lambda x: x*x)\n",
    "squares.collect()\n",
    "squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## filter(func)\t\n",
    "Return a new dataset formed by selecting those elements of the source on which func returns true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evens = digits.filter(lambda x: x % 2 == 0)\n",
    "evens.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## flatMap(func)\t\n",
    "Similar to map, but each input item can be mapped to 0 or more output items (so func should return a Seq rather than a single item)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 2, 2, 5, 2, 3, 7, 2, 2, 2, 3, 3]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def factors(nr):\n",
    "    i = 2\n",
    "    factors = []\n",
    "    while i <= nr:\n",
    "        if (nr % i) == 0:\n",
    "            factors.append(i)\n",
    "            nr = nr / i\n",
    "        else:\n",
    "            i = i + 1\n",
    "    return factors\n",
    "primes = digits.flatMap(factors)\n",
    "primes.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## distinct()\n",
    "Return a new RDD that contains the distinct elements of a RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 5, 7]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primes=primes.distinct()\n",
    "primes.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " ## sample()\n",
    "Return a sampled subset of this RDD.\n",
    "\n",
    "Parameters\n",
    "- withReplacement – can elements be sampled multiple times (replaced when sampled out)\n",
    "- fraction – expected size of the sample as a fraction of this RDD’s size without replacement: probability that each element is chosen; fraction must be [0, 1] with replacement: expected number of times each element is chosen; fraction must be >= 0\n",
    "- seed – seed for the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 6, 8]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.sample(False,0.2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## union()\n",
    "Return a new dataset that contains the union of the elements in the source dataset and the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8, 1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds = digits.filter(lambda x: x % 2 == 1)\n",
    "yy = evens.union(odds)\n",
    "yy.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## intersection()\n",
    "Return a new RDD that contains the intersection of elements in the source dataset and the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 9]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersects=odds.intersection(squares)\n",
    "intersects.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## cartesian()\n",
    "When called on datasets of types T and U, returns a dataset of (T, U) pairs (all pairs of elements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 3),\n",
       " (0, 5),\n",
       " (0, 7),\n",
       " (0, 9),\n",
       " (2, 1),\n",
       " (4, 1),\n",
       " (2, 3),\n",
       " (2, 5),\n",
       " (4, 3),\n",
       " (4, 5),\n",
       " (2, 7),\n",
       " (2, 9),\n",
       " (4, 7),\n",
       " (4, 9),\n",
       " (6, 1),\n",
       " (8, 1),\n",
       " (6, 3),\n",
       " (6, 5),\n",
       " (8, 3),\n",
       " (8, 5),\n",
       " (6, 7),\n",
       " (6, 9),\n",
       " (8, 7),\n",
       " (8, 9)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart=evens.cartesian(odds)\n",
    "cart.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## groupByKey()\n",
    "When called on a dataset of (K, V) pairs, returns a dataset of (K, Iterable<V>) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, <pyspark.resultiterable.ResultIterable at 0x7f8f2d1a1f90>),\n",
       " (2, <pyspark.resultiterable.ResultIterable at 0x7f8f2d1a1d90>),\n",
       " (4, <pyspark.resultiterable.ResultIterable at 0x7f8f2d1a1c50>),\n",
       " (6, <pyspark.resultiterable.ResultIterable at 0x7f8f2d1a1e10>),\n",
       " (8, <pyspark.resultiterable.ResultIterable at 0x7f8f546efd50>)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cartgroup=cart.groupByKey()\n",
    "cartgroup.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## reduce(func)\n",
    "Aggregate the elements of the dataset using a function func (which takes two arguments and returns one). The function should be commutative and associative so that it can be computed correctly in parallel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumOfDigits=digits.reduce(lambda a,b:a+b)\n",
    "sumOfDigits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 3),\n",
       " (0, 5),\n",
       " (0, 7),\n",
       " (0, 9),\n",
       " (2, 1),\n",
       " (4, 1),\n",
       " (2, 3),\n",
       " (2, 5),\n",
       " (4, 3),\n",
       " (4, 5),\n",
       " (2, 7),\n",
       " (2, 9),\n",
       " (4, 7),\n",
       " (4, 9),\n",
       " (6, 1),\n",
       " (8, 1),\n",
       " (6, 3),\n",
       " (6, 5),\n",
       " (8, 3),\n",
       " (8, 5),\n",
       " (6, 7),\n",
       " (6, 9),\n",
       " (8, 7),\n",
       " (8, 9)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {0: 5, 2: 5, 4: 5, 6: 5, 8: 5})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, 4.5, 9], [5, 5])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.histogram(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "scroll": "true",
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
